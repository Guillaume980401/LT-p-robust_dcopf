{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bae2847-6bf0-4b4c-97d1-c04897a56260",
   "metadata": {},
   "source": [
    "# Numerical Experiments - 5-bus case\n",
    "\n",
    "\n",
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610088ed-25a9-41b4-9986-d7f123ab2bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Robert Mieth, 2023\n",
    "# robert.mieth@rutgers.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47d246-b0e4-4c1f-be18-891ac3ddf8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from itertools import product\n",
    "\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import torch\n",
    "\n",
    "# from tqdm.notebook import tqdm, trange\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a592af1-6177-472d-92b7-bb783fc05c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load some global settings\n",
    "\n",
    "from settings5 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c41e1-8c0b-4c7f-b878-4765c2dbfa28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Power system data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5261502-5d74-4d68-b674-7b590163e6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters of matpower case 5\n",
    "\n",
    "d = np.array([0.0, 3.0, 3.0, 4.0, 0.0])\n",
    "pmax = np.array([0.4, 1.7, 5.2, 2.0, 6.0])\n",
    "pmin = np.zeros(len(pmax))\n",
    "smax = np.array([4.0, 1.9, 2.2, 1.0, 1.0, 2.4])\n",
    "ptdf_str  = '-0.193917 0.475895   0.348989  0.0  -0.159538;'\n",
    "ptdf_str += '-0.437588  -0.258343  -0.189451  0.0  -0.36001;'\n",
    "ptdf_str += '-0.368495  -0.217552  -0.159538  0.0   0.519548;'\n",
    "ptdf_str += '-0.193917  -0.524105   0.348989  0.0  -0.159538;'\n",
    "ptdf_str += '-0.193917  -0.524105  -0.651011  0.0  -0.159538;'\n",
    "ptdf_str += '0.368495   0.217552   0.159538  0.0   0.48045'\n",
    "ptdf = np.matrix(ptdf_str)\n",
    "cE = np.array([14.0, 15.0, 30.0, 40.0, 10.0]) # linear cost\n",
    "cE_quad = np.sqrt(cE * 0.1) # quadratic cost\n",
    "cR = np.array([80., 80., 15., 30., 80.])\n",
    "basemva = 100\n",
    "genloc = np.array([1, 1, 3, 4, 5]) -1\n",
    "windloc = np.array([3, 5]) - 1  # standard wind farm location\n",
    "# windloc = np.array([3, 2]) - 1  # configuration B\n",
    "w = np.array([1.0, 1.5])\n",
    "w_cap = np.array([2.0, 3.0])\n",
    "G = len(genloc)\n",
    "D = len(windloc)\n",
    "L = ptdf.shape[0]\n",
    "B = ptdf.shape[1]\n",
    "gen2bus = np.zeros((B,G))\n",
    "for g, bus in enumerate(genloc):\n",
    "    gen2bus[bus, g] = 1\n",
    "wind2bus = np.zeros((B,D))\n",
    "for u, bus in enumerate(windloc):\n",
    "    wind2bus[bus, u] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e60ff-ad42-4ce8-bc2a-4d8abdd58cbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Operational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc083dce-b6cd-4bff-9cad-cc2f93c94da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def box_robust_dcopf_problem_param(mu_init, sigma_init, demand, wind, allow_slack=False, quadratic_cost=False, gamma=0):\n",
    "\n",
    "\n",
    "    # some settings\n",
    "    A_base = 10\n",
    "    slack_base = 10\n",
    "    obj_base = basemva/10\n",
    "    \n",
    "    FR = 0.8 # reduction of line capacity\n",
    "    \n",
    "    # define mean and uncertainty of wind power injections as parameters\n",
    "    mu = cp.Parameter(D, value=mu_init, name=\"mu\")\n",
    "    sigma = cp.Parameter(D, value=sigma_init, name=\"sigma\")\n",
    "    \n",
    "     # define load as a parameter\n",
    "    d = cp.Parameter(B, value=demand, name=\"demand\")\n",
    "    w = cp.Parameter(D, value=wind, name=\"wind\")\n",
    "        \n",
    "    # main variables\n",
    "    p  = cp.Variable(G, pos=True, name=\"p\")\n",
    "    rp = cp.Variable(G, pos=True, name=\"rp\")\n",
    "    rm = cp.Variable(G, pos=True, name=\"rm\")\n",
    "    A  = cp.Variable((G,D), pos=True, name=\"A\")\n",
    "    fRAMp = cp.Variable(L, pos=True, name=\"fRAMp\")\n",
    "    fRAMm = cp.Variable(L, pos=True, name=\"fRAMm\")\n",
    "\n",
    "    # aux. variables for robust constraints\n",
    "    z = cp.Variable((2*G + 2*L,D), name=\"z\")\n",
    "    \n",
    "    # aux. variables to ensure feasibility\n",
    "    if allow_slack:\n",
    "        slack = cp.Variable(2*G + 2*L, pos=True, name=\"slack\")\n",
    "    \n",
    "    # basic det constraints\n",
    "    flow = ptdf @ ((gen2bus @ p) + (wind2bus @ w) - d)\n",
    "    consts = [\n",
    "        cp.sum(p) + cp.sum(w) == cp.sum(d),\n",
    "        p + rp <= pmax,\n",
    "        p - rm >= pmin, \n",
    "        A.T @ np.ones(G) == np.ones(D)*A_base,\n",
    "         flow + fRAMp == smax * FR,\n",
    "        -flow + fRAMm == smax * FR\n",
    "    ]\n",
    "\n",
    "    # box support constraints\n",
    "    for g in range(G):\n",
    "        if allow_slack:\n",
    "            consts.append((mu.T @ (-A[g,:]/A_base)) + (sigma.T @ A[g,:]/A_base) <= rp[g] + slack[g]/slack_base)\n",
    "        else:\n",
    "            consts.append((mu.T @ (-A[g,:]/A_base)) + (sigma.T @ A[g,:]/A_base) <= rp[g])\n",
    "        if allow_slack:\n",
    "            consts.append((mu.T @ (A[g,:]/A_base)) + (sigma.T @  A[g,:]/A_base) <= rm[g] + slack[g+G]/slack_base)\n",
    "        else:\n",
    "            consts.append((mu.T @ (A[g,:]/A_base)) + (sigma.T @  A[g,:]/A_base) <= rm[g])\n",
    "    for l in range(L):\n",
    "        Bl = cp.reshape(ptdf[l,:] @ (wind2bus - (gen2bus @ A/A_base)), D)\n",
    "        # Bl = (ptdf[l,:] @ (wind2bus - (gen2bus @ A))).T\n",
    "        if allow_slack:\n",
    "            consts.append(mu.T @ Bl + (sigma.T @ z[l,:]) <= fRAMp[l] + slack[2*G+l]/slack_base)\n",
    "        else:\n",
    "            consts.append(mu.T @ Bl + (sigma.T @ z[l,:]) <= fRAMp[l])\n",
    "        consts.append(z[l,:] >= Bl)\n",
    "        consts.append(z[l,:] >= -Bl)\n",
    "        if allow_slack:\n",
    "            consts.append(mu.T @ -Bl + (sigma.T @ z[L+l,:]) <= fRAMm[l] + slack[2*G+L+l]/slack_base)   \n",
    "        else:\n",
    "            consts.append(mu.T @ -Bl + (sigma.T @ z[L+l,:]) <= fRAMm[l])\n",
    "        consts.append(z[L+l,:] >= -Bl)\n",
    "        consts.append(z[L+l,:] >= Bl)\n",
    "\n",
    "    # objective\n",
    "    cost_E = (cE.T @ p)\n",
    "    if quadratic_cost:\n",
    "        cost_E_quad = cp.sum_squares(cp.multiply(cE_quad, p))\n",
    "    else:\n",
    "        cost_E_quad = 0                         \n",
    "    cost_R = (cR.T @ (rp + rm))\n",
    "    objective = cost_E + cost_E_quad + cost_R\n",
    "    \n",
    "    if allow_slack:\n",
    "        thevars = [p, rp, rm, A, fRAMp, fRAMm, z, slack]\n",
    "    else:\n",
    "        thevars = [p, rp, rm, A, fRAMp, fRAMm, z]\n",
    "    x = cp.hstack([v.flatten() for v in thevars])\n",
    "    regularization = gamma * cp.sum_squares(x)\n",
    "    objective += regularization\n",
    "    \n",
    "    if allow_slack:\n",
    "        penalty_slack = cp.sum(slack) * obj_base * 1e3\n",
    "        objective += penalty_slack\n",
    "    \n",
    "    theprob = cp.Problem(cp.Minimize(objective), consts)\n",
    "    \n",
    "    return theprob, thevars, [d, w, mu, sigma], consts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b4ac3-cfe8-4a4a-a4b0-b1bf329f1b17",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Error data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4138d-4c34-472a-9977-e7921281d3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_historical_data(w_fcst, N=1000, SEED=42, metadata=False, corr=0.1, rel_sigma=[0.15, 0.15]):\n",
    "    mu = np.zeros(D)\n",
    "    rel_sigma = np.array(rel_sigma)\n",
    "    correlation = np.matrix([[1.0, corr],[corr, 1.0]])\n",
    "    sigma = w_fcst * rel_sigma\n",
    "    Sigma = np.diag(sigma)*correlation*np.diag(sigma)\n",
    "    # sample\n",
    "    # np.random.seed(seed=SEED)\n",
    "    hist_data = np.random.multivariate_normal(mu, Sigma, size=N)\n",
    "    # truncate\n",
    "    for j in range(D):\n",
    "        hist_data[(hist_data[:,j] >= w_cap[j] - w_fcst[j]),j] = w_cap[j] - w_fcst[j]\n",
    "        hist_data[(hist_data[:,j] <= -w_fcst[j]),j] = -w_fcst[j]\n",
    "    if metadata:\n",
    "        return hist_data, mu, Sigma\n",
    "    else:\n",
    "        return hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f647f-be8e-4d0d-b77b-925b2138ed4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "TEST_PERC = 0.25\n",
    "CORR = 0.5\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=10)\n",
    "\n",
    "# some other settings\n",
    "d_range = [0.5, 1.1]\n",
    "w_range = [0.5, 1.1]\n",
    "\n",
    "# define bins\n",
    "nbins = 10\n",
    "bins = [np.linspace(w_range[0]*w[i], w_range[1]*w[i], nbins+1) for i in range(D)]\n",
    "\n",
    "# create a large set of forecast errors from different wind scenarios\n",
    "N_samples = 2000\n",
    "train_errors_in_bins = [[[] for bi in range(nbins+3)] for i in range(D)]\n",
    "all_errors = []\n",
    "for i in trange(N_samples):\n",
    "    d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "    w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "    cur_data = create_historical_data(w_scenario_np, N=1, corr=CORR)[0]\n",
    "    for i in range(D):\n",
    "        cur_bin = np.digitize(w_scenario_np[i], bins[i])\n",
    "        train_errors_in_bins[i][cur_bin].append(cur_data[i])\n",
    "    all_errors.append(cur_data)\n",
    "all_errors = np.vstack(all_errors)\n",
    "\n",
    "train, test = train_test_split(all_errors, test_size=int(all_errors.shape[0]*TEST_PERC), random_state=SEED)\n",
    "\n",
    "train_data = torch.tensor(train, dtype=DTYPE)\n",
    "test_data = torch.tensor(test, dtype=DTYPE)\n",
    "\n",
    "# init based on stdv\n",
    "mu_init = np.mean(train, axis=0)\n",
    "sigma_init =np.std(train, axis=0)/2\n",
    "\n",
    "# percentile-based set paramters\n",
    "perc= 10 # in percent\n",
    "percupper = np.percentile(train, 100-perc, axis=0)\n",
    "perclower = np.percentile(train, perc, axis=0)\n",
    "mu_base_perc = (percupper + perclower) / 2\n",
    "sigma_base_perc = mu_init + ((percupper - perclower) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16be83-4a3e-4559-b09c-46a866cfbad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94bae6-366b-4fc7-879e-08aa27def160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob, _, theparams, _ = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, allow_slack=False, quadratic_cost=True)\n",
    "prob.solve(solver=\"ECOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42592c27-06a4-4ad7-8838-b89989b4f56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test feasibility for a few random scenarios\n",
    "d_range = [0.5, 1.1]\n",
    "w_range = [0.5, 1.1]\n",
    "d_scenario = np.random.uniform(*d_range, B) * d\n",
    "w_scenario = np.random.uniform(*w_range, D) * w\n",
    "\n",
    "theparams[0].value = d_scenario\n",
    "theparams[1].value = w_scenario\n",
    "prob.solve(solver='ECOS', warm_start=True)\n",
    "print(prob.status)\n",
    "print(f'Objective value:  {prob.value:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc440e6-9b07-4e0f-884f-058a000a87de",
   "metadata": {},
   "source": [
    "## Cost-based loss\n",
    "\n",
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758df97-1108-4873-be3c-989992df8486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use relu to discard negative values\n",
    "nonneg = torch.nn.ReLU(inplace=False)\n",
    "\n",
    "def expected_cost(var_values, hist_data_tch, gamma=0):\n",
    "    \n",
    "    # some settings\n",
    "    A_base = 10\n",
    "    slack_base = 10\n",
    "    obj_base = basemva/10\n",
    "    \n",
    "    p = var_values[0]\n",
    "    rp = var_values[1]\n",
    "    rm = var_values[2]\n",
    "    A = var_values[3]\n",
    "    fRAMp = var_values[4]\n",
    "    fRAMm = var_values[5]\n",
    "    if len(var_values) == 8:\n",
    "        slack = var_values[-1]\n",
    "    else:\n",
    "        slack = torch.tensor(0)\n",
    "    varlist = [p, rp, rm, A, fRAMp, fRAMm, slack]\n",
    "    x = torch.hstack([v.flatten() for v in varlist])\n",
    "        \n",
    "    # expected first stage cost\n",
    "    opf_cost = (torch.dot(p, cE_tch) + torch.dot(rp + rm, cR_tch)) \n",
    "    opf_cost += torch.sum(slack) * obj_base * 1e3\n",
    "\n",
    "    # expected reserve violation cost\n",
    "    reaction_gen = torch.matmul(A/A_base, hist_data_tch.T)\n",
    "    expected_rp_viol_cost = torch.sum(nonneg(-reaction_gen.T - rp[None, :]).mean(axis=0) * cM_tch)\n",
    "    expected_rm_viol_cost = torch.sum(nonneg(reaction_gen.T - rm[None, :]).mean(axis=0) * cM_tch)\n",
    "    reaction_branch = torch.matmul(torch.matmul(ptdf_tch,(wind2bus_tch - torch.matmul(gen2bus_tch, A/A_base))), hist_data_tch.T)\n",
    "    expected_framp_viol_cost = torch.sum(nonneg(reaction_branch.T - fRAMp[None, :]).mean(axis=0) * cM_tch)\n",
    "    expected_framm_viol_cost = torch.sum(nonneg(-reaction_branch.T - fRAMm[None, :]).mean(axis=0) * cM_tch)\n",
    "    \n",
    "    regularization = gamma*torch.sum(torch.square(x))\n",
    "    \n",
    "    return opf_cost + expected_rp_viol_cost + expected_rm_viol_cost + expected_framp_viol_cost + expected_framm_viol_cost + regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b793155-44a6-4c12-bf70-5a2e1a74b321",
   "metadata": {},
   "source": [
    "### Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68372843-67de-4a9e-8e10-7a66c1d54a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some additonal settings\n",
    "LR = 5e-6\n",
    "LMOM = 0.3\n",
    "GAMMA = 0.\n",
    "cM = 2000\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# prepare parameters \n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up base model for comparison\n",
    "base_prob, _, _, _ = box_robust_dcopf_problem_param(mu_base_perc, sigma_base_perc, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_tch = torch.tensor(sigma_init, dtype=DTYPE, requires_grad=True)\n",
    "mu_tch = torch.tensor(mu_init, dtype=DTYPE, requires_grad=True)\n",
    "\n",
    "# set up SGD \n",
    "opt = torch.optim.SGD([mu_tch, sigma_tch], lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "loss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        \n",
    "        for batch in range(BATCHSIZE):\n",
    "            # create net demand scenario \n",
    "            d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "            d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "            w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "            w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "            scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "        \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu_tch, sigma_tch]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss = expected_cost(var_values, train_data, gamma=GAMMA)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "            \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # step the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu\": mu_tch.detach().numpy(),\n",
    "            \"sigma\": sigma_tch.detach().numpy(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        ep_looper.set_postfix(loss=loss.item())\n",
    "        \n",
    "results_without_prescription = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_during_training, label='train')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('step')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db30167-e5fc-4914-b283-8ec32e7f36b4",
   "metadata": {},
   "source": [
    "### P-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c4a4bd-e41e-4729-a126-edc8f92882de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some additonal settings\n",
    "LR = 1e-6\n",
    "LMOM = 0.3\n",
    "GAMMA = 0.1\n",
    "cM = 2000\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# prepare parameters \n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up base model for comparison\n",
    "base_prob, _, _, _ = box_robust_dcopf_problem_param(mu_base_perc, sigma_base_perc, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "sigma_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "sigma_prescriptor.bias.data = torch.tensor(sigma_init, dtype=DTYPE)\n",
    "mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "mu_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "mu_prescriptor.bias.data = torch.tensor(mu_init, dtype=DTYPE)\n",
    "\n",
    "# set up SGD \n",
    "parameters = list(mu_prescriptor.parameters()) + list(sigma_prescriptor.parameters())\n",
    "opt = torch.optim.SGD(parameters, lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "loss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        oosloss = torch.tensor(0., dtype=DTYPE)\n",
    "        baseloss = torch.tensor(0., dtype=DTYPE)\n",
    "    \n",
    "        for batch in range(BATCHSIZE):\n",
    "            # create net demand scenario \n",
    "            d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "            d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "            w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "            w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "            scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "            \n",
    "            # prescribe the the set size\n",
    "            mu = mu_prescriptor(scenario_vector.float())\n",
    "            sigma = sigma_prescriptor(scenario_vector.float())\n",
    "        \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu, sigma]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss = expected_cost(var_values, train_data, gamma=GAMMA)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "              \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # step the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu_pres_weight\": mu_prescriptor.weight.data.detach(),\n",
    "            \"mu_pres_bias\": mu_prescriptor.bias.data.detach(),\n",
    "            \"sigma_pres_weight\": sigma_prescriptor.weight.data.detach(),\n",
    "            \"sigma_pres_bias\": sigma_prescriptor.bias.data.detach(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        ep_looper.set_postfix(loss=loss.item())\n",
    "\n",
    "results_with_prescription = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_during_training, label='train')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('step')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb27a9c-ac51-446b-a7af-409c534d4280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DTYPE = torch.float32\n",
    "\n",
    "# now lets try with prescriptor model\n",
    "# cM = 1000\n",
    "cM = 2000\n",
    "\n",
    "MAX_EPOCH = 100\n",
    "BATCHSIZE = 20\n",
    "REL_DATA_BATCH = 0.2\n",
    "LR = 1e-6\n",
    "LMOM = 0.3\n",
    "GAMMA = 0.1\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# some other settings\n",
    "d_range = [0.5, 1.1]\n",
    "w_range = [0.5, 1.1]\n",
    "\n",
    "# exogenous parameters \n",
    "# TODO all global and weird now\n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up base model for comparison\n",
    "base_prob, _, _, _ = box_robust_dcopf_problem_param(mu_base_perc, sigma_base_perc, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "sigma_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "sigma_prescriptor.bias.data = torch.tensor(sigma_init, dtype=DTYPE)\n",
    "mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "mu_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "mu_prescriptor.bias.data = torch.tensor(mu_init, dtype=DTYPE)\n",
    "\n",
    "# set up SGD \n",
    "parameters = list(mu_prescriptor.parameters()) + list(sigma_prescriptor.parameters())\n",
    "opt = torch.optim.SGD(parameters, lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "loss_during_training = []\n",
    "# oosloss_during_training = []\n",
    "# baseloss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "# for epoch in trange(MAX_EPOCH, desc=\"Training progress\", unit=\"epoch\"):\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        oosloss = torch.tensor(0., dtype=DTYPE)\n",
    "        baseloss = torch.tensor(0., dtype=DTYPE)\n",
    "    \n",
    "         # create net demand scenario \n",
    "        d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "        d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "        w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "        w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "        scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "\n",
    "        # prescribe the the set size\n",
    "        mu = mu_prescriptor(scenario_vector.float())\n",
    "        sigma = sigma_prescriptor(scenario_vector.float())\n",
    "\n",
    "        for batch in range(BATCHSIZE):\n",
    "            \n",
    "            batch_data_ids = np.random.randint(0, train.shape[0], int(train_data.shape[0]*REL_DATA_BATCH))   \n",
    "           \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu, sigma]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss = expected_cost(var_values, train_data[batch_data_ids], gamma=GAMMA)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "            \n",
    "#             # calculate oos loss\n",
    "#             tempoosloss = expected_cost(var_values, test_data, gamma=GAMMA)\n",
    "#             oosloss = oosloss + tempoosloss/BATCHSIZE\n",
    "            \n",
    "#             # calculate base loss\n",
    "#             base_prob.parameters()[0].value = w_scenario_np\n",
    "#             base_prob.parameters()[1].value = d_scenario_np\n",
    "#             base_prob.solve(solver='ECOS', warm_start=True)\n",
    "#             base_var_values = [torch.tensor(v.value, dtype=DTYPE) for v in base_prob.variables()]\n",
    "#             tempbaseloss = expected_cost(base_var_values, test_data, gamma=GAMMA)\n",
    "#             baseloss = baseloss + tempbaseloss/BATCHSIZE\n",
    "              \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # step the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu_pres_weight\": mu_prescriptor.weight.data.detach(),\n",
    "            \"mu_pres_bias\": mu_prescriptor.bias.data.detach(),\n",
    "            \"sigma_pres_weight\": sigma_prescriptor.weight.data.detach(),\n",
    "            \"sigma_pres_bias\": sigma_prescriptor.bias.data.detach(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        # oosloss_during_training.append(oosloss.item())\n",
    "        # baseloss_during_training.append(baseloss.item())\n",
    "        ep_looper.set_postfix(loss=loss.item())\n",
    "        # if epoch % 10 == 9:\n",
    "            # print(f'Epoch: {epoch} | Loss: {loss_during_training[-1]} | mu: {mu_during_training[-1]} | sigma: {sigma_during_training[-1]}')\n",
    "results_with_prescription_outer_sample = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_during_training, label='train')\n",
    "# ax.plot(oosloss_during_training, label='test')\n",
    "# ax.plot(baseloss_during_training, label='base')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('step')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40009124-598f-4f20-8424-af1ac2a0caf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.select(train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef6715-c1ea-4535-89f4-76a1559e5ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4767524-7376-45a4-99e3-5a24258def8c",
   "metadata": {},
   "source": [
    "### P-Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d0d4c-0f26-47e3-b2f9-2df0c82d6cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some additonal settings\n",
    "LR = 1e-6\n",
    "LMOM = 0.3\n",
    "GAMMA = 0.\n",
    "cM = 2000\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# prepare parameters \n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "sigma_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "sigma_prescriptor.bias.data = torch.tensor(sigma_init, dtype=DTYPE)\n",
    "mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "mu_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "mu_prescriptor.bias.data = torch.tensor(mu_init, dtype=DTYPE)\n",
    "\n",
    "# set up SGD \n",
    "parameters = list(mu_prescriptor.parameters()) + list(sigma_prescriptor.parameters())\n",
    "opt = torch.optim.SGD(parameters, lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "loss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        \n",
    "        for batch in range(BATCHSIZE):\n",
    "            # create net demand scenario \n",
    "            d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "            d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "            w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "            w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "            scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "            \n",
    "            # prescribe the the set size\n",
    "            mu = mu_prescriptor(scenario_vector.float())\n",
    "            sigma = sigma_prescriptor(scenario_vector.float())\n",
    "        \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu, sigma]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # create forecast errors based on wind scenario\n",
    "            cur_data = create_historical_data(w_scenario_np, N=200, corr=0.5)\n",
    "            cur_data = torch.tensor(cur_data, dtype=DTYPE)\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "              \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # step the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu_pres_weight\": mu_prescriptor.weight.data.detach(),\n",
    "            \"mu_pres_bias\": mu_prescriptor.bias.data.detach(),\n",
    "            \"sigma_pres_weight\": sigma_prescriptor.weight.data.detach(),\n",
    "            \"sigma_pres_bias\": sigma_prescriptor.bias.data.detach(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        ep_looper.set_postfix(loss=loss.item())\n",
    "\n",
    "results_with_prescription_and_cond_error = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_during_training)\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dca54f-af13-4d6e-a961-e291fe1fcddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### P-Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b057763-522a-43aa-99fa-089ed1888d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some additional settings\n",
    "LR = 1e-6\n",
    "LMOM = 0.3\n",
    "GAMMA = 0.\n",
    "cM = 2000\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# exogenous parameters \n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "sigma_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "sigma_prescriptor.bias.data = torch.tensor(sigma_init, dtype=DTYPE)\n",
    "mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "mu_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "mu_prescriptor.bias.data = torch.tensor(mu_init, dtype=DTYPE)\n",
    "\n",
    "# set up SGD \n",
    "parameters = list(mu_prescriptor.parameters()) + list(sigma_prescriptor.parameters())\n",
    "opt = torch.optim.SGD(parameters, lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "loss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        \n",
    "        for batch in range(BATCHSIZE):\n",
    "            # create net demand scenario \n",
    "            d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "            d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "            w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "            w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "            scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "            \n",
    "            # prescribe the the set size\n",
    "            mu = mu_prescriptor(scenario_vector.float())\n",
    "            sigma = sigma_prescriptor(scenario_vector.float())\n",
    "        \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu, sigma]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # select forecast errors from wind scenario\n",
    "            cur_bins = [np.digitize(w_scenario_np[i], bins[i]) for i in range(D)]\n",
    "            cur_errors = [train_errors_in_bins[i][cur_bins[i]] for i in range(D)]\n",
    "            min_len = min((len(a) for a in cur_errors))\n",
    "            cur_errors = [a[:min_len] for a in cur_errors]\n",
    "            cur_data = np.column_stack(cur_errors)\n",
    "            cur_data = torch.tensor(cur_data, dtype=DTYPE)\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "              \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # step the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu_pres_weight\": mu_prescriptor.weight.data.detach(),\n",
    "            \"mu_pres_bias\": mu_prescriptor.bias.data.detach(),\n",
    "            \"sigma_pres_weight\": sigma_prescriptor.weight.data.detach(),\n",
    "            \"sigma_pres_bias\": sigma_prescriptor.bias.data.detach(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        ep_looper.set_postfix(loss=loss.item())\n",
    "\n",
    "results_with_prescription_and_imp_cond_error = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(loss_during_training)\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88900cb0-8663-44e7-b911-a43b80203aee",
   "metadata": {},
   "source": [
    "### OOS testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d8e8d-31f2-4df9-9684-8e95a65ae2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in oos gamma is always zero\n",
    "GAMMA = 0.\n",
    "cM = 2000\n",
    "\n",
    "# get final training\n",
    "def get_prescriptors(training_results):\n",
    "    final_training_epoch = training_results.iloc[-1]\n",
    "    sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "    sigma_prescriptor.weight.data = final_training_epoch.sigma_pres_weight\n",
    "    sigma_prescriptor.bias.data = final_training_epoch.sigma_pres_bias\n",
    "    mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "    mu_prescriptor.weight.data = final_training_epoch.mu_pres_weight\n",
    "    mu_prescriptor.bias.data = final_training_epoch.mu_pres_bias\n",
    "    return mu_prescriptor, sigma_prescriptor\n",
    "\n",
    "# create model\n",
    "prob, thevars, theparams, _ = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "\n",
    "pu_scale = 100\n",
    "N_OOS = 500\n",
    "oos_loss_base = []\n",
    "oos_loss_full = []\n",
    "oos_loss_single = []\n",
    "oos_loss_presc = []\n",
    "oos_loss_presc_cond = []\n",
    "oos_loss_presc_imp_cond = []\n",
    "for oos in trange(N_OOS):\n",
    "\n",
    "    # create a scenario\n",
    "    d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "    w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "    d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "    w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "    scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "    # create a single error occurence\n",
    "    cur_error = create_historical_data(w_scenario_np, N=12, corr=CORR)\n",
    "    cur_data = torch.tensor(cur_error, dtype=DTYPE)\n",
    "\n",
    "    ## base model\n",
    "    theparams[0].value = d_scenario_np\n",
    "    theparams[1].value = w_scenario_np\n",
    "    theparams[2].value = mu_base_perc\n",
    "    theparams[3].value = sigma_base_perc\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    # compute loss for the prescribed model\n",
    "    loss_base = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "    oos_loss_base.append(loss_base.item() * pu_scale)\n",
    "    \n",
    "    ## full robust\n",
    "    mine = np.min(train, axis=0)\n",
    "    maxe = np.min(train, axis=0)\n",
    "    theparams[2].value = (maxe + mine) / 2\n",
    "    theparams[3].value = mu_init + ((maxe - mine) / 2)\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    # compute loss for the prescribed model\n",
    "    loss_full = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "    oos_loss_full.append(loss_full.item() * pu_scale)\n",
    "    \n",
    "    ## one size fits all\n",
    "    final_epoch = results_without_prescription.iloc[-1]\n",
    "    theparams[2].value = final_epoch.mu\n",
    "    theparams[3].value = final_epoch.sigma\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    # compute loss for the prescribed model\n",
    "    loss_single = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "    oos_loss_single.append(loss_single.item() * pu_scale)\n",
    "    \n",
    "    ## prescribed model\n",
    "    # parametrize prescribed model\n",
    "    mu_presc, sigma_presc = get_prescriptors(results_with_prescription)\n",
    "    # mu_presc, sigma_presc = get_prescriptors(results_with_prescription_outer_sample)\n",
    "    theparams[2].value = mu_presc(scenario_vector).detach().numpy()\n",
    "    theparams[3].value = sigma_presc(scenario_vector).detach().numpy()\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    # compute loss for the prescribed model\n",
    "    loss_presc = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "    oos_loss_presc.append(loss_presc.item() * pu_scale)\n",
    "    \n",
    "    ## prescribed model with perfect knowledge of conditional distributon\n",
    "    mu_presc_cond, sigma_presc_cond = get_prescriptors(results_with_prescription_and_cond_error)\n",
    "    theparams[2].value = mu_presc_cond(scenario_vector).detach().numpy()\n",
    "    theparams[3].value = sigma_presc_cond(scenario_vector).detach().numpy()\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    # compute loss for the prescribed model\n",
    "    loss_presc_cond = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "    oos_loss_presc_cond.append(loss_presc_cond.item() * pu_scale)\n",
    "    \n",
    "    ## prescribed model with IMperfect knowledge of conditional distributon\n",
    "    mu_presc_imp_cond, sigma_presc_imp_cond = get_prescriptors(results_with_prescription_and_imp_cond_error)\n",
    "    theparams[2].value = mu_presc_imp_cond(scenario_vector).detach().numpy()\n",
    "    theparams[3].value = sigma_presc_imp_cond(scenario_vector).detach().numpy()\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    # compute loss for the prescribed model\n",
    "    loss_presc_imp_cond = expected_cost(var_values, cur_data, gamma=GAMMA)\n",
    "    oos_loss_presc_imp_cond.append(loss_presc_imp_cond.item() * pu_scale)\n",
    "\n",
    "    \n",
    "for ci,cn in enumerate(['B', 'Full', 'OSFA', 'P', 'PC', 'PIPC']):\n",
    "    curec = np.mean([oos_loss_base, oos_loss_full, oos_loss_single, oos_loss_presc, oos_loss_presc_cond, oos_loss_presc_imp_cond][ci])\n",
    "    print(f'Expected cost case {cn}: {curec:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829187b1-c603-4f48-a019-8d8855e94e44",
   "metadata": {},
   "source": [
    "## Constraint-based loss\n",
    "\n",
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8fd796-472d-4e00-a5f1-290095971745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cvar_loss(var_values, tau, lam, hist_data_tch, gamma=0., quantile=0.95, target=0., mu=0.):\n",
    "    \n",
    "    # some settings\n",
    "    A_base = 10.\n",
    "    slack_base = 10.\n",
    "    obj_base = basemva/10.\n",
    "    \n",
    "    p = var_values[0]\n",
    "    rp = var_values[1]\n",
    "    rm = var_values[2]\n",
    "    A = var_values[3]\n",
    "    fRAMp = var_values[4]\n",
    "    fRAMm = var_values[5]\n",
    "    if len(var_values) == 8:\n",
    "        slack = var_values[-1]\n",
    "    else:\n",
    "        slack = torch.tensor(0.)\n",
    "    varlist = [p, rp, rm, A, fRAMp, fRAMm, slack]\n",
    "    x = torch.hstack([v.flatten() for v in varlist])\n",
    "        \n",
    "    # expected objective (objectice is deterministic in this case)\n",
    "    enercost = (torch.dot(p, cE_tch) + torch.dot(rp + rm, cR_tch))\n",
    "    slack_penalty = torch.sum(slack) * obj_base * 1e3\n",
    "    reg_penalty = gamma*torch.sum(torch.square(x)) # regularization\n",
    "    opf_cost = enercost + slack_penalty + reg_penalty\n",
    "    \n",
    "    # cvar\n",
    "    reaction_gen = torch.matmul(-A/A_base, hist_data_tch.T)\n",
    "    g_rp = reaction_gen.T - rp[None, :]\n",
    "    g_rm = -reaction_gen.T - rm[None, :]\n",
    "    reaction_branch = torch.matmul(torch.matmul(ptdf_tch,(wind2bus_tch - torch.matmul(gen2bus_tch, A/A_base))), hist_data_tch.T)\n",
    "    g_framp = reaction_branch.T - fRAMp[None, :]\n",
    "    g_framm = -reaction_branch.T - fRAMm[None, :]\n",
    "    g = torch.cat((g_rp, g_rm, g_framp, g_framm), dim=1)\n",
    "    g_max, _ = torch.max(g, dim=1)\n",
    "    \n",
    "    cvar = torch.mean(torch.maximum(g_max - tau, torch.tensor(0.,dtype=DTYPE)))/(1-quantile) + tau\n",
    "    \n",
    "    n_violations = sum(g_max > 0.)\n",
    "    total_loss = opf_cost + lam*(cvar - target) + (mu/2)*(cvar - target)**2.\n",
    "    \n",
    "    return total_loss, opf_cost, cvar, n_violations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334181d-69f5-44bf-9cad-4922729cbe4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc7970-0434-46a5-8075-d5c93072cf77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some additional settings\n",
    "LR = 1e-5\n",
    "LMOM = 0.5\n",
    "GAMMA = 0.1\n",
    "cM = 2000\n",
    "\n",
    "CVAR_TARGET = 0.\n",
    "CVAR_QUANT = 0.99 # target level of security\n",
    "\n",
    "MU_INIT = 1.\n",
    "TAU_INIT = 0.\n",
    "LAM_INIT = 500\n",
    "LAM_STEP = 0.1\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# prepare parameters \n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_tch = torch.tensor(sigma_init, dtype=DTYPE, requires_grad=True)\n",
    "mu_tch = torch.tensor(mu_init, dtype=DTYPE, requires_grad=True)\n",
    "\n",
    "# set up auxillary variables\n",
    "tau_tch = torch.tensor(TAU_INIT, dtype=DTYPE, requires_grad=True)\n",
    "lam_tch = torch.tensor(LAM_INIT, dtype=DTYPE)\n",
    "\n",
    "# set up SGD \n",
    "parameters = [mu_tch, sigma_tch, tau_tch]\n",
    "opt = torch.optim.SGD(parameters, lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "loss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        \n",
    "        # aux reset\n",
    "        cvar = torch.tensor(0., dtype=DTYPE)\n",
    "        opfcost = 0.\n",
    "        violations = 0.\n",
    "        \n",
    "        for batch in range(BATCHSIZE):\n",
    "            # create net demand scenario \n",
    "            d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "            d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "            w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "            w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "            scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "        \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu_tch, sigma_tch]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss, tempopf, tempcvar, tempviolations = cvar_loss(var_values, tau_tch, lam_tch, train_data, \n",
    "                                                            gamma=0., quantile=CVAR_QUANT, target=CVAR_TARGET, mu=1.)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "            cvar = cvar + tempcvar.detach()/BATCHSIZE\n",
    "            opfcost = opfcost + tempopf.item()/BATCHSIZE\n",
    "            violations = violations + tempviolations.item()/BATCHSIZE\n",
    "          \n",
    "        # compute empirical violation probability\n",
    "        violation_prob = violations/train_data.size()[0]\n",
    "        \n",
    "        # update lambda\n",
    "        lam_tch = torch.maximum(lam_tch + LAM_STEP * cvar, torch.tensor(0., dtype=DTYPE)) \n",
    "\n",
    "        # backpropagate the lagrangian\n",
    "        loss.backward()\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu\": mu_tch.detach().numpy(),\n",
    "            \"sigma\": sigma_tch.detach().numpy(),\n",
    "            \"violation_prob\": violation_prob,\n",
    "            \"opfcost\": opfcost,\n",
    "            \"cvar\": cvar.detach().numpy().copy(),\n",
    "            \"tau_grad\": tau_tch.grad, \n",
    "            \"tau\": tau_tch.detach().numpy().copy(),\n",
    "            \"lam\": lam_tch.detach().numpy().copy(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        ep_looper.set_postfix(violation_prob=violation_prob, cvar=cvar.detach().numpy().copy())\n",
    "        \n",
    "        # step and reset the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "                \n",
    "results_cvar_without_prescription = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, axs = plt.subplots(3,1)\n",
    "fig.tight_layout(pad=1.5)\n",
    "training_viol_prob = training_data_df.violation_prob.to_numpy()\n",
    "training_cvar = training_data_df.cvar.to_numpy()\n",
    "training_opfcost = training_data_df.opfcost.to_numpy()\n",
    "axs[0].plot(training_viol_prob, label='train')\n",
    "axs[0].set_ylabel('violation probability')\n",
    "axs[0].set_xlabel('step')\n",
    "axs[1].plot(training_cvar, label='train')\n",
    "axs[1].set_ylabel('cvar')\n",
    "axs[1].set_xlabel('step')\n",
    "axs[2].plot(training_opfcost, label='train')\n",
    "axs[2].set_ylabel('opfcost')\n",
    "axs[2].set_xlabel('step')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac04bb8-ca29-415e-845d-9d836324f3d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### P-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d14201-e95f-4644-8946-593f64179037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some addtional settings\n",
    "LR = 1e-6\n",
    "LMOM = 0.\n",
    "GAMMA = 0.1\n",
    "cM = 2000\n",
    "\n",
    "CVAR_TARGET = 0.\n",
    "CVAR_QUANT = 0.99 # target level of security\n",
    "\n",
    "MU_INIT = 1.\n",
    "TAU_INIT = 0.\n",
    "LAM_INIT = 500\n",
    "LAM_STEP = 0.1\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=SEED)\n",
    "\n",
    "# prepare parameters \n",
    "cE_tch = torch.tensor(cE, dtype=DTYPE)\n",
    "cR_tch = torch.tensor(cR, dtype=DTYPE)\n",
    "cM_tch = torch.tensor(cM, dtype=DTYPE)\n",
    "ptdf_tch = torch.tensor(ptdf, dtype=DTYPE)\n",
    "gen2bus_tch = torch.tensor(gen2bus, dtype=DTYPE)\n",
    "wind2bus_tch = torch.tensor(wind2bus, dtype=DTYPE)\n",
    "zero_tch = torch.tensor(0, dtype=DTYPE)\n",
    "\n",
    "# set up the layer\n",
    "inner, vs, params, consts = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "inner_cvxpylayer = CvxpyLayer(inner, parameters=inner.parameters(), variables=inner.variables())\n",
    "\n",
    "# set up the prescriptor\n",
    "sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "sigma_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "sigma_prescriptor.bias.data = torch.tensor(sigma_init, dtype=DTYPE)\n",
    "mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "mu_prescriptor.weight.data = torch.zeros((D, B+D))\n",
    "mu_prescriptor.bias.data = torch.tensor(mu_init, dtype=DTYPE)\n",
    "\n",
    "# set up auxillary variables\n",
    "tau_tch = torch.tensor(TAU_INIT, dtype=DTYPE, requires_grad=True)\n",
    "# lam_tch = torch.tensor(LAM_INIT, dtype=DTYPE)\n",
    "lam_tch = LAM_INIT\n",
    "\n",
    "# set up SGD \n",
    "parameters = list(mu_prescriptor.parameters()) + list(sigma_prescriptor.parameters()) + [tau_tch]\n",
    "opt = torch.optim.SGD(parameters, lr=LR, momentum=LMOM) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, patience=5)\n",
    "\n",
    "#train\n",
    "lang_mu = MU_INIT\n",
    "loss_during_training = []\n",
    "training_data_df = pd.DataFrame()\n",
    "with trange(MAX_EPOCH) as ep_looper:\n",
    "    for epoch in ep_looper:\n",
    "        ep_looper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        # reset loss\n",
    "        loss = torch.tensor(0., dtype=DTYPE)\n",
    "        \n",
    "        # aux reset\n",
    "        cvar = torch.tensor(0., dtype=DTYPE)\n",
    "        opfcost = 0.\n",
    "        violations = 0.\n",
    "        \n",
    "        for batch in range(BATCHSIZE):\n",
    "            # create net demand scenario \n",
    "            d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "            d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "            w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "            w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "            scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "            \n",
    "            # prescribe the the set size\n",
    "            mu = mu_prescriptor(scenario_vector)\n",
    "            sigma = sigma_prescriptor(scenario_vector)\n",
    "            # sigma = torch.maximum(sigma_prescriptor(scenario_vector.float()), torch.tensor(0.))\n",
    "        \n",
    "            # compute current inner solution\n",
    "            opf_params = [w_scenario, d_scenario, mu, sigma]\n",
    "            var_values = inner_cvxpylayer(*opf_params,  solver_args={'solve_method': \"ECOS\"})\n",
    "            \n",
    "            # calculate loss\n",
    "            temploss, tempopf, tempcvar, tempviolations = cvar_loss(var_values, tau_tch, lam_tch, train_data, \n",
    "                                                            gamma=0., quantile=CVAR_QUANT, target=CVAR_TARGET, mu=1.)\n",
    "            loss = loss + temploss/BATCHSIZE\n",
    "            cvar = cvar + tempcvar.detach()/BATCHSIZE\n",
    "            opfcost = opfcost + tempopf.item()/BATCHSIZE\n",
    "            violations = violations + tempviolations.item()/BATCHSIZE\n",
    "          \n",
    "        # compute empirical violation probability\n",
    "        violation_prob = violations/train_data.size()[0]\n",
    "        \n",
    "        # update lambda\n",
    "        lam_tch = torch.maximum(lam_tch + LAM_STEP * cvar, torch.tensor(0., dtype=DTYPE)) \n",
    "\n",
    "        # backpropagate the lagrangian\n",
    "        loss.backward()\n",
    "        \n",
    "        # some analysis and reporting\n",
    "        current_results = pd.Series({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"mu_pres_weight\": mu_prescriptor.weight.data.detach(),\n",
    "            \"mu_pres_bias\": mu_prescriptor.bias.data.detach(),\n",
    "            \"sigma_pres_weight\": sigma_prescriptor.weight.data.detach(),\n",
    "            \"sigma_pres_bias\": sigma_prescriptor.bias.data.detach(),\n",
    "            \"violation_prob\": violation_prob,\n",
    "            \"opfcost\": opfcost,\n",
    "            \"cvar\": cvar.detach().numpy().copy(),\n",
    "            \"tau_grad\": tau_tch.grad, \n",
    "            \"tau\": tau_tch.detach().numpy().copy(),\n",
    "            \"lam\": lam_tch.detach().numpy().copy(),\n",
    "        })\n",
    "        training_data_df = pd.concat([training_data_df, current_results.to_frame().T], ignore_index=True)\n",
    "        loss_during_training.append(loss.item())\n",
    "        ep_looper.set_postfix(violation_prob=violation_prob, cvar=cvar.detach().numpy().copy())\n",
    "        \n",
    "        # step and reset the SGD\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        scheduler.step(loss)\n",
    "                \n",
    "results_cvar_with_prescription = training_data_df.copy()\n",
    "            \n",
    "# some final reporting    \n",
    "fig, axs = plt.subplots(3,1)\n",
    "fig.tight_layout(pad=1.5)\n",
    "training_viol_prob = training_data_df.violation_prob.to_numpy()\n",
    "training_cvar = training_data_df.cvar.to_numpy()\n",
    "training_opfcost = training_data_df.opfcost.to_numpy()\n",
    "axs[0].plot(training_viol_prob, label='train')\n",
    "axs[0].set_ylabel('violation probability')\n",
    "axs[0].set_xlabel('step')\n",
    "axs[1].plot(training_cvar, label='train')\n",
    "axs[1].set_ylabel('cvar')\n",
    "axs[1].set_xlabel('step')\n",
    "axs[2].plot(training_opfcost, label='train')\n",
    "axs[2].set_ylabel('opfcost')\n",
    "axs[2].set_xlabel('step')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9dd840-df75-4366-b15b-947b1488f6bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OOS testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef10b0-ec50-4498-ac00-32b5192045da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in oos gamma is always zero\n",
    "GAMMA = 0.\n",
    "cM = 2000\n",
    "\n",
    "# reset randomness\n",
    "np.random.seed(seed=2)\n",
    "\n",
    "# get final training\n",
    "def get_prescriptors(training_results):\n",
    "    final_training_epoch = training_results.iloc[-1]\n",
    "    sigma_prescriptor = torch.nn.Linear(B+D, D)\n",
    "    sigma_prescriptor.weight.data = final_training_epoch.sigma_pres_weight\n",
    "    sigma_prescriptor.bias.data = final_training_epoch.sigma_pres_bias\n",
    "    mu_prescriptor = torch.nn.Linear(B+D, D)\n",
    "    mu_prescriptor.weight.data = final_training_epoch.mu_pres_weight\n",
    "    mu_prescriptor.bias.data = final_training_epoch.mu_pres_bias\n",
    "    return mu_prescriptor, sigma_prescriptor\n",
    "\n",
    "# create model\n",
    "prob, thevars, theparams, _ = box_robust_dcopf_problem_param(mu_init, sigma_init, d, w, gamma=GAMMA, allow_slack=True, quadratic_cost=False)\n",
    "\n",
    "pu_scale = 100\n",
    "N_OOS = 500\n",
    "oos_violation_prob = 0\n",
    "oos_violation_prob_single = 0\n",
    "oos_set_samples = []\n",
    "oos_errors = []\n",
    "for oos in trange(N_OOS):\n",
    "\n",
    "    # create a scenario\n",
    "    d_scenario_np = np.random.uniform(*d_range, B) * d\n",
    "    w_scenario_np = np.random.uniform(*w_range, D) * w\n",
    "    d_scenario = torch.tensor(d_scenario_np, dtype=DTYPE)\n",
    "    w_scenario = torch.tensor(w_scenario_np, dtype=DTYPE)\n",
    "    scenario_vector = torch.cat((d_scenario, w_scenario))\n",
    "    # create a single error occurence\n",
    "    cur_error = create_historical_data(w_scenario_np, N=1, corr=0.5)\n",
    "    cur_data = torch.tensor(cur_error, dtype=DTYPE)\n",
    "\n",
    "    ## set base parameters\n",
    "    theparams[0].value = d_scenario_np\n",
    "    theparams[1].value = w_scenario_np\n",
    "    \n",
    "    ## single model\n",
    "    final_epoch = results_without_prescription.iloc[-1]\n",
    "    theparams[2].value = final_epoch.mu\n",
    "    theparams[3].value = final_epoch.sigma\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    _, _, _, violation = cvar_loss(var_values, tau_tch, lam_tch, cur_data, gamma=0., quantile=CVAR_QUANT, target=CVAR_TARGET) \n",
    "    oos_violation_prob_single += violation/N_OOS\n",
    "    \n",
    "    ## prescribed model\n",
    "    # parametrize prescribed model\n",
    "    mu_presc, sigma_presc = get_prescriptors(results_cvar_with_prescription)\n",
    "    mu_current = mu_presc(scenario_vector).detach().numpy()\n",
    "    sigma_current = sigma_presc(scenario_vector).detach().numpy()\n",
    "    theparams[2].value = mu_current\n",
    "    theparams[3].value = sigma_current\n",
    "    prob.solve(solver='ECOS', warm_start=True)\n",
    "    var_values = [torch.tensor(v.value, dtype=DTYPE) for v in thevars]\n",
    "    _, _, _, violation = cvar_loss(var_values, tau_tch, lam_tch, cur_data, gamma=0., quantile=CVAR_QUANT, target=CVAR_TARGET) \n",
    "    oos_violation_prob += violation/N_OOS\n",
    "    \n",
    "    oos_set_samples.append({\"mu\": mu_current, \"sigma\": sigma_current})\n",
    "    oos_errors.append(cur_data)\n",
    " \n",
    "print(f'Empirical oos violation probability single: {oos_violation_prob_single:.3f}')\n",
    "print(f'Empirical oos violation probability prescription: {oos_violation_prob:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-context_learning",
   "language": "python",
   "name": "venv-context_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
